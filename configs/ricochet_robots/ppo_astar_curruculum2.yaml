# PPO curriculum training configuration for Ricochet Robots
game:
  type: "ricochet_robots"
  # Game parameters will be controlled by curriculum
  board_size: 16  # Max size (overridden by curriculum)
  num_robots: 4   # Max robots (overridden by curriculum)
  reward_per_move: -1.0
  reward_goal: 100.0

agent:
  type: "ppo"
  learning_rate: 0.0003
  n_steps: 1024
  batch_size: 64
  n_epochs: 10
  gamma: 0.99
  gae_lambda: 0.95
  clip_range: 0.2
  ent_coef: 0.01
  vf_coef: 0.5
  max_grad_norm: 0.5
  verbose: 0

encoder:
  type: "planar"
  # type: "flat_array"
  # type: "rgb"

environment:
  max_episode_steps: 100  # Increased for harder levels
  curriculum_update_freq: 1  # Update curriculum every episode


training:
  total_timesteps: 100000  # Increased for PPO training
  eval_freq: 100
  save_freq: 25000
  eval_episodes: 100
  curriculum_update_freq: 100  # Update curriculum every 100 timesteps
  log_freq: 100
  # Optional: log an agent rollout video to Weights & Biases periodically
  # Set rollout_log_freq > 0 to enable. Keep infrequent to save storage.
  rollout_log_freq: 500   # log every 20k steps (disabled by default)
  rollout_max_steps: 50     # max steps per logged rollout
  rollout_fps: 2            # playback fps for the video
  # Optional: enable CPU profiling for a full breakdown (use sparingly; slows training)
  profile: true
  profile_output: ./profiles/train_profile.prof
logging:
  use_wandb: false
  wandb_project: "rl-board-games"
  wandb_run_name: "ppo-ricochet-curriculum"

checkpoints:
  save_dir: "./checkpoints/"

# Example: switch to alternative A* plan-based curriculum (uncomment to use)
curriculum:
  type: "astar_plan"
  evaluation_episodes: 50
  levels:  # PlanCurriculumLevel entries
    - name: "R1-L1"
      min_solve_length: 1
      max_solve_length: 1
      success_threshold: 0.90
      board_size: 8
      num_robots: 4
      max_walls: 16
      episodes_per_evaluation: 40
      board_size_min: 16
      board_size_max: 16
      # New lower bounds (optional)
      # min_total_moves: 1
      min_robots_moved: 1
      # max_total_moves: 1
      max_robots_moved: 1
    - name: "R1-L2"
      min_solve_length: 1
      max_solve_length: 2
      success_threshold: 0.90
      board_size: 8
      num_robots: 4
      max_walls: 16
      episodes_per_evaluation: 40
      board_size_min: 16
      board_size_max: 16
      # New lower bounds (optional)
      # min_total_moves: 1
      min_robots_moved: 1
      # max_total_moves: 2
      max_robots_moved: 1
    - name: "R1-L3"
      min_solve_length: 2
      max_solve_length: 3
      success_threshold: 0.90
      board_size: 8
      num_robots: 4
      max_walls: 16
      episodes_per_evaluation: 40
      board_size_min: 16
      board_size_max: 16
      # min_total_moves: 2
      min_robots_moved: 1
      # max_total_moves: 3
      max_robots_moved: 1
    - name: "R1-L5"
      min_solve_length: 4
      max_solve_length: 5
      success_threshold: 0.90
      board_size: 8
      num_robots: 4
      max_walls: 16
      episodes_per_evaluation: 40
      board_size_min: 16
      board_size_max: 16
      # min_total_moves: 4
      min_robots_moved: 1
      # max_total_moves: 5
      max_robots_moved: 1
    - name: "R2-L3"
      min_solve_length: 2
      max_solve_length: 3
      success_threshold: 0.90
      board_size: 8
      num_robots: 4
      max_walls: 16
      episodes_per_evaluation: 40
      board_size_min: 16
      board_size_max: 16
      # min_total_moves: 1
      min_robots_moved: 2
      # max_total_moves: 5
      max_robots_moved: 2
    - name: "R2-L5"
      min_solve_length: 4
      max_solve_length: 5
      success_threshold: 0.90
      board_size: 8
      num_robots: 4
      max_walls: 16
      episodes_per_evaluation: 40
      board_size_min: 16
      board_size_max: 16
      # min_total_moves: 4
      min_robots_moved: 2
      # max_total_moves: 5
      max_robots_moved: 2